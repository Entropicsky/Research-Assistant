# Perplexity Research Suite - Environment Configuration Example
# Rename this file to .env and fill in your actual API keys

# Required API Keys
PERPLEXITY_API_KEY=your-perplexity-api-key-here
FIRECRAWL_API_KEY=your-firecrawl-api-key-here
OPENAI_API_KEY=your-openai-api-key-here

# Models Configuration
# Model options for Perplexity:
# - sonar-medium-online: Good balance of speed and quality (recommended for most cases)
# - sonar-deep-research: Best quality for research, slower and more expensive
# - mixtral-8x7b-instruct: Good for content formatting
PERPLEXITY_RESEARCH_MODEL=sonar-deep-research
PERPLEXITY_CLEANUP_MODEL=sonar-pro

# API Rate Limiting and Error Handling
# Adjust these settings to control rate limit protection
API_MAX_RETRIES=3                 # Maximum number of retry attempts for rate-limited calls
API_INITIAL_RETRY_DELAY=5.0       # Starting delay in seconds before retrying
API_MAX_RETRY_DELAY=60.0          # Maximum delay cap in seconds

# Performance Tuning
# Adjust these settings to balance speed vs. API rate limits
RATE_LIMIT_QUESTIONS_PER_WORKER=7 # Higher value = fewer workers (reduces parallel API calls)
THREAD_STAGGER_DELAY=5.0           # Seconds to wait between starting workers (0 = no delay)
MAX_CITATIONS=50                   # Maximum number of citations to process (prioritizes most referenced ones)
CITATION_TIMEOUT=300               # Maximum time in seconds to wait for a citation to process (prevents hanging)

# OpenAI Integration Settings
ENABLE_OPENAI_INTEGRATION=true     # Set to 'true' to enable OpenAI file upload and vector store creation
RESEARCH_PROJECTS_FILE=research_projects.json  # Path to the JSON file for tracking research projects
OPENAI_FILE_UPLOAD_TIMEOUT=60      # Maximum time in seconds to wait for a file upload
OPENAI_VECTORSTORE_CREATION_TIMEOUT=60  # Maximum time in seconds to wait for vector store creation
OPENAI_PROCESSING_MAX_CHECKS=20    # Maximum number of checks for file processing status
OPENAI_PROCESSING_CHECK_INTERVAL=10  # Seconds to wait between checks for file processing status

# Streamlit App Settings
OPENAI_CHAT_MODEL=gpt-4o-mini      # Default model for the chat interface
MAX_SEARCH_RESULTS=5               # Maximum number of search results to return from vector search

# Additional Settings (optional)
# DEFAULT_TEMPERATURE=0.2         # Controls randomness in responses (0.0-1.0)